import glob
import os
import sys

Import('env')
env = env.Clone()
env.Append(CPPPATH=['#build/fpl2cc']) # because we use/test generated headers

# there exist some .cc-based tests of fpl parts:
run_cc_tests(env);

# The "fpl_iteself" directory contains fpl source files which
# we compile and check the output of.  They may deliberately
# contain/generate errors, and thus may or may not be expected to
# compile, but should give reasonable error messages etc.
for expected in Glob('fpl_itself/*.fpl_expect'):
    basename, foo = os.path.splitext(expected.name)
    target_path = os.path.dirname(expected.get_abspath())
    source  = 'fpl_itself/' + basename + '.fpl'
    ccfile  = target_path + '/' + basename + '.cc'
    capfile = target_path + '/' + basename + '.fpl_result'
    success = target_path + '/' + basename + '.success'
    env.CaptureFplCompile(
        [ ccfile, capfile ],  [ source ],
        CAPFILE=capfile, IGNORE_EXIT=True, QUIET=True
    )
    env.CompareOut(success, [ expected, capfile ])

#
# fpl language tests:
#
# dependencies:
#   [src language].test/[src language]: [src language].cc
#   [src language].test/[src language].cc: [src language].fpl
#   [src language].test/[test name].result: [src language].test/[test name].[src language] [src language]
#   [src language].test/[test name].success: [src language].test/[test name].expect [src language].test/[test name].result
#
# So each test language is defined by an .fpl file,
# and then each test consists of a source file for that language and
# a .expect file with the corresponding expected .result file.
# This lets us black-box test the fpl compiler for various cases.
#
# references (these were hard to find):
#   scons' idea of a target:
#     https://scons.org/doc/latest/HTML/scons-api/SCons.Node/#
#   action variables:
#     https://scons.org/doc/production/HTML/scons-user.html#app-variables
#

# (Note this is the scons Glob, so it returns target-path dirs)
test_dirs = Glob('*.test')

if env['LLVM_VERSION']:
    llvms = Glob('llvm*')
    if len(llvms):
        test_dirs.append(*llvms)
    else:
        print(f"no llvm tests found", file=sys.stderr)

if len(test_dirs) <= 0:
    warnings.warn(f"No tests found in ")
else:
    # If we're on the main branch, generate profiling info.
    # Profiling info is tied to the commit ID of the current
    # HEAD.
    # This works well if the workflow is to do development on
    # a branch, and integrate said development onto main
    # as a single commit (via squashing and/or picking),
    # which is how I like to work.
    # Obviously the above assumes git, but whatever.
    profile_dir = None
    if git_branch() == 'master':
        this_dir = os.path.dirname(test_dirs[0].get_path())
        profile=this_dir + '/' + test_name + '.prof_out'
        # profile_dir = os.path.dirname(test_dirs[0].relpath) # on linux, complains no relpath
        profile_dir = os.path.dirname(test_dirs[0].get_path())

    run_language_tests(env, test_dirs, profile_dir)


