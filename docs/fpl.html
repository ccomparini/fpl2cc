<html>
  <head>
    <title>fpl features and syntax</title>
    <style>
      .gel {
        font-weight: bold;
      }
      .optional {
        font-style: italic;
      }
    </style>
  </head>
  <body>
    <div>
      Fpl is a lex/yacc/bison alternative, born of my frustration with
      those tools and of reading about other parser generators (such
      as https://pdos.csail.mit.edu/~baford/packrat/thesis/).
      <p>A more logical excuse for fpl is that at some point jest needs
      to be rewritten in jest, and if I use existing parser generator
      languages, I'm going to be tied to c or whatever language those
      parser generators generate. So I need something which will generate
      jest (unless I want to code the parser by hand, which is possible).
    </div>
    <div>
      Key differences from other existing parser generators:
      <ul>
        <li>In contrast to how grammars are specified both in academic
        literature and in most parser-generator languages, in fpl,
        <b>the tokens to match are specified on the left, and what
        to do with the match is on the right.</b>  I find this infinitely
        more intuitive - rules are generally read as "&lt;<i>match</i>&gt;
        is a/an &lt;<i>production name</i>&gt;, and is impemented in
        such and so a fashion".  The language structure is on the left,
        the first part you read, as it's the important part.  The
        probably-more-mutable (and anyway less important) implementation
        details go in the least prominent place (on the right),
        where they belong.
        <li>Scanning and parsing are not separate in fpl.  Token
        specifications (e.g. regular expressions) are done in the
        relevant gramatical rules.
        Equivalent<sup><a href="#not_really_equivalent">*</a></sup>
        tokens are folded together behind the scenes.  In practice,
        this means fewer files (and scanner/parser languages) to
        have to deal with.
        <li>Comment parsing can be specified in the fpl (see @comment_style,
        @separator directives, below)
        <li>Parsers generated by fpl will attempt to recognize one
        or more "goal" grammar elements <b>and then halt, leaving
        the input read position at the end of the last thing
        recognized</b>.  This allows callers to mix top down and
        bottom up parsing - bottom up constructs can be specified
        in fpl and used from top-down (or other) parsers to parse
        specific cases.  Among the use cases for this are embedded
        doc comments, other languages, etc.  Maybe I can slap together
        some examples.
      </ul>
    </div>
    <div>
      fpl gramatical elements:
      <ul>
        <li> <span class="gel">#</span> comment
        <li> <span class="gel">@</span> <a href="#directives">directive</a>
        <li> <span class="gel">+{</span><span class="optional">code</span><span class="gel">}+</span> code block
        <li> <span class="optional"></span><span class="optional">code</span><span class="gel">}+</span> code block
        <li> <span class="optional"></span><a href="#rules">production rule</a></span>
        <li> XXX sub-fpl files fill in
      </ul>
    </div>
    <div id="directives">
      <span class="subhead">Directives</span>
      <p>Valid directives are:
      <ul>
        <li id="comment_style_directive"><code>@comment_style</code></li>
        <li id="default_action_directive"><code>@default_action</code></li>
        <li id="default_main_directive"><code>@default_main</code></li>
        <li id="post_parse_directive"><code>@post_parse</code></li>
        <li id="produces_directive"><code>@produces</code> <b>(required)</b> - tells the parser
        generator what type is to be returned from code generation
        rules and from the generated parser itself.  For c++, the
        type must be to_string compatible - if it's not already
        (and I'm really sorry about this), you must specify a
        <code>to_string()</code> function in a
        <a href="code_block">code block</a> prior to any rules.
        <p>For example:
        <pre>
          <code>
          +{
              std::string to_string(const &amp;my_type x) {
                  return x.convert_to_string_or_whatever();
              }
          }+</code>
        </pre></li>
        <br>See <a href=#examples">examples</a>.
        <li id="separator_directive"><code>@separator</code></li>
      </ul>
    </div>
    <div id="rules">
      <span class="subhead">Production rules</span>
      <p>Production rules are of the form:
      <pre>
        &lt;<a href="#expressions">exprs</a> to match&gt; -&gt; &lt;production name&gt; { &lt;code&gt; }
                   or
        &lt;<a href="#exprsessions">exprs</a> to match&gt; -&gt; &lt;production name&gt; ;
      </pre>

      <div id="exprs">
        Expressions may be any of:
        <ul>
          <li> quoted string (eg <code>"xxx"</code> or <code>'yyy'</code>)
          <li> regular expression within slashes (eg /0x[0-9a-fA-F]+/)
          <li> names of other productions as plain text (no spaces)
        </ul>
        <p>The first 2 effectively specify scan tokens.  Single or double quotes
        are equivalent, and specify an exact match to look for.  Regular
        expressions can be used to specify 
        The third case specifies 
        <p> Expressions may be followed directly by (no space) one of
        *, +, or ? to mean 0-or-more, 1-or-more, or 0-or-1 respectively.
      </div>
    </div>
    <div id="examples">
      <span class="subhead">Examples:</span>
      <pre>
        # a very basic calculator

        @produces int

        aexpr '+' mexpr -&gt; aexpr +{ return arg_0 + arg_2; }+
        aexpr '-' mexpr -&gt; aexpr +{ return arg_0 - arg_2; }+
        mexpr           -&gt; aexpr ;

        mexpr '*' term  -&gt; mexpr +{ return arg_0 * arg_2; }+
        mexpr '/' term  -&gt; mexpr +{ return arg_0 / arg_2; }+
        mexpr '%' term  -&gt; mexpr +{ return arg_0 % arg_2; }+
        term            -&gt; mexpr ;

        '-' term        -&gt; term +{ return -arg_1; }+
        '(' aexpr ')'   -&gt; term +{ return arg_1;  }+
        /[0-9]+/        -&gt; term +{
            return std::stoi(arg_0);
        }+

      </pre>
    </div>
    <hr>
    <div id="footnotes">
      <div id="not_really_equivalent"><sup>*</sup>
        With regular expressions, you can trick fpl2cc into having
        ambiguous, "secretly" equivalent, or overlapping tokens.
        For example, it won't know that <code>/[1-3]/</code> and
        <code>/[123]/</code> are equivalent or that
        <code>/[a-z]+/</code> and <code>/[a-f]+/<code> can both
        match some of the same strings.
        In practice this mostly does not matter, but I recommend you
        keep your regexes tidy and minimal to avoid any surprises.
    </div>
  </body>
</html>
